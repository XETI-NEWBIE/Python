{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YjpFqpVPDis_sk3AocK8eDIkMqS7c_g0",
      "authorship_tag": "ABX9TyNKdndv/j65x7gybZORraWR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XETI-NEWBIE/Python/blob/main/LSTM%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_%EC%8B%9D%EC%9D%8C%EC%97%85%EC%9E%A5_%EB%A9%94%EB%89%B4_%EC%88%98%EC%9A%94_%EC%98%88%EC%B8%A1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "try:\n",
        "    import torch\n",
        "    print(\"Torch:\", torch.__version__)\n",
        "except Exception as e:\n",
        "    print(\"Torch import failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cuUD-V1I8Ah",
        "outputId": "8d48a12c-aa34-4883-f776-7da7a77f612c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Torch: 2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip cache purge\n",
        "# Python 3.12 호환 버전 설치 (CUDA 포함 휠)\n",
        "!pip install --upgrade torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZH1vdW8I712",
        "outputId": "3f553d20-bad4-470a-c70e-535bab9adcd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: torchaudio 2.8.0+cu126\n",
            "Uninstalling torchaudio-2.8.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (799.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, torchaudio\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vlg8YHbI7pT",
        "outputId": "81b4a42f-558b-4a2e-9381-4244477caaa3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.4.0+cu121 | CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for p in [\"/data/train\", \"/data/test\"]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "# 여러분의 파일을 /content에 두셨다면 다음처럼 옮기거나 복사해 주세요 (예시)\n",
        "# !cp /content/train.csv /data/train/train.csv\n",
        "# !cp /content/sample_submission.csv /data/sample_submission.csv\n",
        "# !cp /content/TEST_*.csv /data/test/"
      ],
      "metadata": {
        "id": "KX2W-GjLJHkE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Imports & Device\n",
        "# -------------------------\n",
        "import os, re, glob, math, random, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "if 'DEVICE' not in globals():\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DEVICE:\", DEVICE, \"| CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt7x03MfHHnB",
        "outputId": "950c15ff-b4cc-4c71-bc88-1dfd14b690c1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cpu | CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "DATA_DIR   = \"/data\"\n",
        "TRAIN_PATH = f\"{DATA_DIR}/train/train.csv\"\n",
        "TEST_GLOB  = f\"{DATA_DIR}/test/TEST_*.csv\"\n",
        "SAMPLE_SUB = f\"{DATA_DIR}/sample_submission.csv\"\n",
        "\n",
        "LOOKBACK = 28\n",
        "HORIZON  = 7\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS     = 35\n",
        "LR         = 1e-3        # 안정 수렴을 위해 살짝 낮춤\n",
        "PATIENCE   = 6\n",
        "\n",
        "# 손실 혼합 가중치 (SMAPE에 더 무게)\n",
        "ALPHA_SM   = 0.7         # 최종 loss = ALPHA_SM*SMAPE + (1-ALPHA_SM)*MSE\n",
        "\n",
        "# 업장 가중치(담하, 미라시아 강화) - 과도하면 흔들릴 수 있으니 적당히\n",
        "IMPORTANT_STORES = {\"담하\", \"미라시아\"}\n",
        "IMPORTANT_WEIGHT = 1.5\n",
        "DEFAULT_WEIGHT   = 1.0\n",
        "\n",
        "# 재현성\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "qFG7w9TxHKEh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Utils\n",
        "# -------------------------\n",
        "def parse_shop(name: str) -> str:\n",
        "    if isinstance(name, str):\n",
        "        return name.split(\"_\", 1)[0]\n",
        "    return str(name)\n",
        "\n",
        "def _clean_counts(v):\n",
        "    v = np.asarray(v, dtype=float)\n",
        "    v = np.where(np.isfinite(v), v, 0.0)\n",
        "    v = np.maximum(v, 0.0)\n",
        "    return v\n",
        "\n",
        "def smape_numpy(y_true, y_pred, eps=1e-5):\n",
        "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
        "    mask = (y_true != 0)\n",
        "    if mask.sum() == 0:\n",
        "        return 0.0\n",
        "    num = 2.0 * np.abs(y_true[mask] - y_pred[mask])\n",
        "    den = np.abs(y_true[mask]) + np.abs(y_pred[mask]) + eps\n",
        "    return float(np.mean(num / den))\n",
        "\n",
        "def smape_torch_weighted(y_true, y_pred, w, eps=1e-5):\n",
        "    # y_true,y_pred: (B,HZ) - ORIGINAL scale / w:(B,)\n",
        "    y_true = torch.nan_to_num(y_true, nan=0.0, posinf=0.0, neginf=0.0).clamp_min(0.0)\n",
        "    y_pred = torch.nan_to_num(y_pred, nan=0.0, posinf=0.0, neginf=0.0).clamp_min(0.0)\n",
        "    mask = (y_true != 0.0).float()\n",
        "    num = 2.0 * torch.abs(y_true - y_pred)\n",
        "    den = torch.abs(y_true) + torch.abs(y_pred) + eps\n",
        "    sm  = (num / den) * mask                       # (B,HZ)\n",
        "    per_sample = sm.sum(dim=1) / torch.clamp(mask.sum(dim=1), min=1.0)  # (B,)\n",
        "    w = w.view(-1)\n",
        "    return (per_sample * w).sum() / torch.clamp(w.sum(), min=1.0)\n"
      ],
      "metadata": {
        "id": "GCoVEPROHN7E"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Weighted SMAPE (store-importance aware)\n",
        "# -------------------------\n",
        "def smape_torch_weighted(y_true, y_pred, w, eps=1e-5):\n",
        "    \"\"\"\n",
        "    y_true, y_pred: (B, HZ) on ORIGINAL scale\n",
        "    w: (B,) sample weight (e.g., 담하/미라시아 2.0, others 1.0)\n",
        "    - 실제=0인 타임스텝은 제외\n",
        "    - 각 샘플(HZ 평균) 후 샘플 가중 평균\n",
        "    \"\"\"\n",
        "    # 보호: NaN/Inf 제거 및 음수 제거\n",
        "    y_true = torch.nan_to_num(y_true, nan=0.0, posinf=0.0, neginf=0.0).clamp_min(0.0)\n",
        "    y_pred = torch.nan_to_num(y_pred, nan=0.0, posinf=0.0, neginf=0.0).clamp_min(0.0)\n",
        "\n",
        "    mask = (y_true != 0.0).float()  # (B, HZ)\n",
        "    num = 2.0 * torch.abs(y_true - y_pred)\n",
        "    den = torch.abs(y_true) + torch.abs(y_pred) + eps\n",
        "    sm = (num / den) * mask  # (B, HZ)\n",
        "\n",
        "    per_sample = sm.sum(dim=1) / torch.clamp(mask.sum(dim=1), min=1.0)  # (B,)\n",
        "    w = w.view(-1)  # (B,)\n",
        "    return (per_sample * w).sum() / torch.clamp(w.sum(), min=1.0)\n"
      ],
      "metadata": {
        "id": "m25DB48vZu-_"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Data Preparation (확장 피처)\n",
        "# -------------------------\n",
        "# 1) train 로드 & 기본 전처리\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "train[\"영업일자\"] = pd.to_datetime(train[\"영업일자\"])\n",
        "train[\"영업장명_메뉴명\"] = train[\"영업장명_메뉴명\"].astype(str)\n",
        "train[\"업장명\"] = train[\"영업장명_메뉴명\"].apply(parse_shop)\n",
        "train = train.sort_values([\"영업장명_메뉴명\", \"영업일자\"]).reset_index(drop=True)\n",
        "\n",
        "# 2) vocab (UNK=0)\n",
        "items = sorted(train[\"영업장명_메뉴명\"].unique().tolist())\n",
        "shops = sorted(train[\"업장명\"].unique().tolist())\n",
        "item2id = {it: i+1 for i, it in enumerate(items)}\n",
        "shop2id = {sp: i+1 for i, sp in enumerate(shops)}\n",
        "UNK_ITEM, UNK_SHOP = 0, 0\n",
        "N_ITEMS = len(item2id) + 1\n",
        "N_SHOPS = len(shop2id) + 1\n",
        "\n",
        "# 3) 윈도우 생성\n",
        "def build_windows_ext(df: pd.DataFrame, lookback=LOOKBACK, horizon=HORIZON):\n",
        "    X, Xrm7, Xrm28 = [], [], []\n",
        "    Xdow, Xmon, Xwoy, Xdoy = [], [], [], []\n",
        "    Fdow, Fmon, Fwoy, Fdoy = [], [], [], []\n",
        "    Y = []\n",
        "    item_list, shop_list, wt_list, scale_list, date_key_list = [], [], [], [], []\n",
        "\n",
        "    for (itm), g in df.groupby(\"영업장명_메뉴명\"):\n",
        "        g = g.sort_values(\"영업일자\")\n",
        "        vals  = _clean_counts(g[\"매출수량\"].values)\n",
        "        dates = pd.to_datetime(g[\"영업일자\"]).values\n",
        "\n",
        "        shop_name = g[\"업장명\"].iloc[0]\n",
        "        sid  = shop2id.get(shop_name, UNK_SHOP)\n",
        "        iid  = item2id.get(itm, UNK_ITEM)\n",
        "        w    = IMPORTANT_WEIGHT if shop_name in IMPORTANT_STORES else DEFAULT_WEIGHT\n",
        "\n",
        "        # 전체 시리즈의 날짜 피처(정수)\n",
        "        dates_pd = pd.to_datetime(g[\"영업일자\"])\n",
        "        d_dow = dates_pd.dt.dayofweek.values.astype(np.int64)          # 0..6\n",
        "        d_mon = dates_pd.dt.month.values.astype(np.int64)              # 1..12\n",
        "        d_woy = dates_pd.dt.isocalendar().week.values.astype(np.int64) # 1..53(54 가능성 대비)\n",
        "        d_doy = dates_pd.dt.dayofyear.values.astype(np.int64)          # 1..365(윤년 366)\n",
        "\n",
        "        # rolling (전구간)\n",
        "        s = pd.Series(vals)\n",
        "        r7  = s.rolling(7,  min_periods=1).mean().values\n",
        "        r28 = s.rolling(28, min_periods=1).mean().values\n",
        "\n",
        "        for t in range(lookback, len(vals) - horizon + 1):\n",
        "            past_idx = slice(t - lookback, t)\n",
        "            fut_idx  = slice(t, t + horizon)\n",
        "\n",
        "            x_seq  = vals[past_idx]\n",
        "            x_rm7  = r7[past_idx]\n",
        "            x_rm28 = r28[past_idx]\n",
        "\n",
        "            x_dow = d_dow[past_idx]\n",
        "            x_mon = d_mon[past_idx]\n",
        "            x_woy = d_woy[past_idx]\n",
        "            x_doy = d_doy[past_idx]\n",
        "\n",
        "            y_seq = vals[fut_idx]\n",
        "\n",
        "            # scale (log1p mean of past window)\n",
        "            x_log    = np.log1p(x_seq)\n",
        "            rm7_log  = np.log1p(np.maximum(x_rm7,  0.0))\n",
        "            rm28_log = np.log1p(np.maximum(x_rm28, 0.0))\n",
        "            y_log    = np.log1p(y_seq)\n",
        "\n",
        "            scale = float(np.nanmean(x_log))\n",
        "            if not np.isfinite(scale) or abs(scale) < 1e-8:\n",
        "                scale = 1.0\n",
        "\n",
        "            X.append((x_log/scale).astype(np.float32))\n",
        "            Xrm7.append((rm7_log/scale).astype(np.float32))\n",
        "            Xrm28.append((rm28_log/scale).astype(np.float32))\n",
        "            Y.append((y_log/scale).astype(np.float32))\n",
        "\n",
        "            # future features from last observed date\n",
        "            last_date = pd.to_datetime(dates[past_idx][-1])\n",
        "            fut_dates = [last_date + pd.Timedelta(days=k) for k in range(1, horizon+1)]\n",
        "            Fdow.append(np.array([d.dayofweek          for d in fut_dates], dtype=np.int64))\n",
        "            Fmon.append(np.array([d.month              for d in fut_dates], dtype=np.int64))\n",
        "            Fwoy.append(np.array([d.isocalendar().week for d in fut_dates], dtype=np.int64))\n",
        "            Fdoy.append(np.array([d.dayofyear          for d in fut_dates], dtype=np.int64))\n",
        "\n",
        "            Xdow.append(x_dow.astype(np.int64))\n",
        "            Xmon.append(x_mon.astype(np.int64))\n",
        "            Xwoy.append(x_woy.astype(np.int64))\n",
        "            Xdoy.append(x_doy.astype(np.int64))\n",
        "\n",
        "            item_list.append(iid)\n",
        "            shop_list.append(sid)\n",
        "            wt_list.append(w)\n",
        "            scale_list.append(scale)\n",
        "            date_key_list.append(pd.to_datetime(dates[t]).to_datetime64())\n",
        "\n",
        "    to_np = lambda L, shape, dtype: np.stack(L) if len(L) else np.empty(shape, dtype)\n",
        "    data = {\n",
        "        \"X\":     to_np(X,     (0, lookback), np.float32),\n",
        "        \"Xrm7\":  to_np(Xrm7,  (0, lookback), np.float32),\n",
        "        \"Xrm28\": to_np(Xrm28, (0, lookback), np.float32),\n",
        "\n",
        "        \"Xdow\":  to_np(Xdow,  (0, lookback), np.int64),\n",
        "        \"Xmon\":  to_np(Xmon,  (0, lookback), np.int64),\n",
        "        \"Xwoy\":  to_np(Xwoy,  (0, lookback), np.int64),\n",
        "        \"Xdoy\":  to_np(Xdoy,  (0, lookback), np.int64),\n",
        "\n",
        "        \"Fdow\":  to_np(Fdow,  (0, horizon),  np.int64),\n",
        "        \"Fmon\":  to_np(Fmon,  (0, horizon),  np.int64),\n",
        "        \"Fwoy\":  to_np(Fwoy,  (0, horizon),  np.int64),\n",
        "        \"Fdoy\":  to_np(Fdoy,  (0, horizon),  np.int64),\n",
        "\n",
        "        \"Y\":     to_np(Y,     (0, horizon),  np.float32),\n",
        "\n",
        "        \"item\":  np.array(item_list,  dtype=np.int64),\n",
        "        \"shop\":  np.array(shop_list,  dtype=np.int64),\n",
        "        \"w\":     np.array(wt_list,    dtype=np.float32),\n",
        "        \"scale\": np.array(scale_list, dtype=np.float32).reshape(-1, 1),\n",
        "        \"date_key\": np.array(date_key_list),\n",
        "    }\n",
        "    return data\n",
        "\n",
        "win = build_windows_ext(train, LOOKBACK, HORIZON)\n",
        "print(\"windows:\", {k: v.shape for k, v in win.items() if isinstance(v, np.ndarray)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_smuqLbX2zg",
        "outputId": "44680aad-3734-4209-d7b2-f25926649c41"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "windows: {'X': (96114, 28), 'Xrm7': (96114, 28), 'Xrm28': (96114, 28), 'Xdow': (96114, 28), 'Xmon': (96114, 28), 'Xwoy': (96114, 28), 'Xdoy': (96114, 28), 'Fdow': (96114, 7), 'Fmon': (96114, 7), 'Fwoy': (96114, 7), 'Fdoy': (96114, 7), 'Y': (96114, 7), 'item': (96114,), 'shop': (96114,), 'w': (96114,), 'scale': (96114, 1), 'date_key': (96114,)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Train/Valid Split (time-based)\n",
        "# -------------------------\n",
        "if len(win[\"date_key\"]) == 0:\n",
        "    raise RuntimeError(\"No training windows were generated. Check data ranges.\")\n",
        "\n",
        "threshold_date = pd.to_datetime(np.quantile(win[\"date_key\"], 0.90))\n",
        "train_idx = (pd.to_datetime(win[\"date_key\"]) < threshold_date).nonzero()[0]\n",
        "valid_idx = (pd.to_datetime(win[\"date_key\"]) >= threshold_date).nonzero()[0]\n",
        "\n",
        "def subset(data, idx):\n",
        "    sub = {}\n",
        "    for k, v in data.items():\n",
        "        sub[k] = v[idx] if isinstance(v, np.ndarray) else v\n",
        "    return sub\n",
        "\n",
        "train_data = subset(win, train_idx)\n",
        "valid_data = subset(win, valid_idx)"
      ],
      "metadata": {
        "id": "4mkV9A3WHSNS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Dataset / DataLoader (확장 피처 16개 반환)\n",
        "# -------------------------\n",
        "class WindowDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.X     = data[\"X\"]\n",
        "        self.Xrm7  = data[\"Xrm7\"]\n",
        "        self.Xrm28 = data[\"Xrm28\"]\n",
        "\n",
        "        self.Xdow  = data[\"Xdow\"]\n",
        "        self.Xmon  = data[\"Xmon\"]\n",
        "        self.Xwoy  = data[\"Xwoy\"]\n",
        "        self.Xdoy  = data[\"Xdoy\"]\n",
        "\n",
        "        self.Fdow  = data[\"Fdow\"]\n",
        "        self.Fmon  = data[\"Fmon\"]\n",
        "        self.Fwoy  = data[\"Fwoy\"]\n",
        "        self.Fdoy  = data[\"Fdoy\"]\n",
        "\n",
        "        self.Y     = data[\"Y\"]\n",
        "        self.item  = data[\"item\"]\n",
        "        self.shop  = data[\"shop\"]\n",
        "        self.w     = data[\"w\"]\n",
        "        self.scale = data[\"scale\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (\n",
        "            torch.from_numpy(self.X[i]).float(),       # (LB,)\n",
        "            torch.from_numpy(self.Xrm7[i]).float(),    # (LB,)\n",
        "            torch.from_numpy(self.Xrm28[i]).float(),   # (LB,)\n",
        "\n",
        "            torch.from_numpy(self.Xdow[i]).long(),     # (LB,)\n",
        "            torch.from_numpy(self.Xmon[i]).long(),     # (LB,)\n",
        "            torch.from_numpy(self.Xwoy[i]).long(),     # (LB,)\n",
        "            torch.from_numpy(self.Xdoy[i]).long(),     # (LB,)\n",
        "\n",
        "            torch.from_numpy(self.Y[i]).float(),       # (HZ,)\n",
        "            torch.tensor(self.item[i]).long(),         # ()\n",
        "            torch.tensor(self.shop[i]).long(),         # ()\n",
        "            torch.tensor(self.w[i]).float(),           # ()\n",
        "            torch.from_numpy(self.scale[i]).float(),   # (1,)\n",
        "\n",
        "            torch.from_numpy(self.Fdow[i]).long(),     # (HZ,)\n",
        "            torch.from_numpy(self.Fmon[i]).long(),     # (HZ,)\n",
        "            torch.from_numpy(self.Fwoy[i]).long(),     # (HZ,)\n",
        "            torch.from_numpy(self.Fdoy[i]).long(),     # (HZ,)\n",
        "        )\n",
        "\n",
        "num_workers = 0 if DEVICE.type == \"cpu\" else 2\n",
        "pin_mem     = (DEVICE.type == \"cuda\")\n",
        "\n",
        "train_loader = DataLoader(WindowDataset(train_data), batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          drop_last=False, num_workers=num_workers, pin_memory=pin_mem)\n",
        "valid_loader = DataLoader(WindowDataset(valid_data), batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          drop_last=False, num_workers=num_workers, pin_memory=pin_mem)\n"
      ],
      "metadata": {
        "id": "rPxH4HOhHWcO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Model (GRU + robust indexing)\n",
        "# -------------------------\n",
        "class GlobalGRUForecaster(nn.Module):\n",
        "    def __init__(self,\n",
        "                 n_items, n_shops,\n",
        "                 item_emb_dim=32, shop_emb_dim=8,\n",
        "                 dow_emb_dim=4, mon_emb_dim=4, woy_emb_dim=6, doy_emb_dim=8,\n",
        "                 horizon_emb_dim=8,\n",
        "                 hidden_dim=128, num_layers=2, horizon=7, dropout=0.15):\n",
        "        super().__init__()\n",
        "        self.horizon = horizon\n",
        "\n",
        "        self.item_emb = nn.Embedding(n_items, item_emb_dim)    # 0..n_items-1 (0=UNK)\n",
        "        self.shop_emb = nn.Embedding(n_shops, shop_emb_dim)    # 0..n_shops-1 (0=UNK)\n",
        "        self.dow_emb  = nn.Embedding(7,   dow_emb_dim)         # 0..6\n",
        "        self.mon_emb  = nn.Embedding(13,  mon_emb_dim)         # 0..12\n",
        "        self.woy_emb  = nn.Embedding(55,  woy_emb_dim)         # 0..54\n",
        "        self.doy_emb  = nn.Embedding(367, doy_emb_dim)         # 0..366\n",
        "        self.h_emb    = nn.Embedding(horizon, horizon_emb_dim)\n",
        "\n",
        "        in_dim = (3\n",
        "                  + dow_emb_dim + mon_emb_dim + woy_emb_dim + doy_emb_dim\n",
        "                  + item_emb_dim + shop_emb_dim)\n",
        "\n",
        "        self.encoder = nn.GRU(\n",
        "            input_size=in_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        dec_in = hidden_dim + item_emb_dim + shop_emb_dim + \\\n",
        "                 dow_emb_dim + mon_emb_dim + woy_emb_dim + doy_emb_dim + horizon_emb_dim\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(dec_in, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _ensure_1d_ids(x: torch.Tensor, B: int):\n",
        "        if not torch.is_tensor(x):\n",
        "            x = torch.tensor(x)\n",
        "        if x.dim() == 0:\n",
        "            x = x.view(1).repeat(B)\n",
        "        elif x.dim() >= 2:\n",
        "            x = x.view(B, -1)[:, 0]\n",
        "        elif x.size(0) != B:\n",
        "            x = x[:1].repeat(B)\n",
        "        return x.long()\n",
        "\n",
        "    @staticmethod\n",
        "    def _clamp_like_emb(x: torch.Tensor, emb: nn.Embedding):\n",
        "        hi = emb.num_embeddings - 1\n",
        "        return x.long().clamp(min=0, max=hi)\n",
        "\n",
        "    def forward(self,\n",
        "                x_seq, x_rm7, x_rm28,           # (B,LB)\n",
        "                x_dow, x_mon, x_woy, x_doy,     # (B,LB)\n",
        "                item_id, shop_id,               # (B,)\n",
        "                f_dow, f_mon, f_woy, f_doy):    # (B,HZ)\n",
        "        B, LB = x_seq.size(0), x_seq.size(1)\n",
        "        HZ = self.horizon\n",
        "\n",
        "        # 안전 가드\n",
        "        item_id = self._ensure_1d_ids(item_id, B)\n",
        "        shop_id = self._ensure_1d_ids(shop_id, B)\n",
        "\n",
        "        x_dow = self._clamp_like_emb(x_dow, self.dow_emb)\n",
        "        x_mon = self._clamp_like_emb(x_mon, self.mon_emb)\n",
        "        x_woy = self._clamp_like_emb(x_woy, self.woy_emb)\n",
        "        x_doy = self._clamp_like_emb(x_doy, self.doy_emb)\n",
        "        f_dow = self._clamp_like_emb(f_dow, self.dow_emb)\n",
        "        f_mon = self._clamp_like_emb(f_mon, self.mon_emb)\n",
        "        f_woy = self._clamp_like_emb(f_woy, self.woy_emb)\n",
        "        f_doy = self._clamp_like_emb(f_doy, self.doy_emb)\n",
        "        item_id = self._clamp_like_emb(item_id, self.item_emb)\n",
        "        shop_id = self._clamp_like_emb(shop_id, self.shop_emb)\n",
        "\n",
        "        # 임베딩\n",
        "        item_e = self.item_emb(item_id)   # (B,Ei) 혹은 (Ei,)\n",
        "        shop_e = self.shop_emb(shop_id)   # (B,Es) 혹은 (Es,)\n",
        "\n",
        "        if item_e.dim() == 1: item_e = item_e.unsqueeze(0).expand(B, -1)\n",
        "        if shop_e.dim() == 1: shop_e = shop_e.unsqueeze(0).expand(B, -1)\n",
        "\n",
        "        x_dow_e = self.dow_emb(x_dow)    # (B,LB,Ed)\n",
        "        x_mon_e = self.mon_emb(x_mon)\n",
        "        x_woy_e = self.woy_emb(x_woy)\n",
        "        x_doy_e = self.doy_emb(x_doy)\n",
        "\n",
        "        # 수치 채널\n",
        "        x_seq  = x_seq.unsqueeze(-1)     # (B,LB,1)\n",
        "        x_rm7  = x_rm7.unsqueeze(-1)\n",
        "        x_rm28 = x_rm28.unsqueeze(-1)\n",
        "\n",
        "        # item/shop 반복\n",
        "        item_rep = item_e.unsqueeze(1).repeat(1, LB, 1)\n",
        "        shop_rep = shop_e.unsqueeze(1).repeat(1, LB, 1)\n",
        "\n",
        "        # 인코더 입력\n",
        "        enc_in = torch.cat([\n",
        "            x_seq, x_rm7, x_rm28,\n",
        "            x_dow_e, x_mon_e, x_woy_e, x_doy_e,\n",
        "            item_rep, shop_rep\n",
        "        ], dim=-1)  # (B,LB,in_dim)\n",
        "\n",
        "        enc_out, _ = self.encoder(enc_in)   # (B,LB,H)\n",
        "        context = enc_out[:, -1, :]         # (B,H)\n",
        "\n",
        "        # 디코더 입력\n",
        "        pos   = torch.arange(HZ, device=enc_in.device).unsqueeze(0).expand(B, HZ)\n",
        "        pos_e = self.h_emb(pos)\n",
        "        f_dow_e = self.dow_emb(f_dow)\n",
        "        f_mon_e = self.mon_emb(f_mon)\n",
        "        f_woy_e = self.woy_emb(f_woy)\n",
        "        f_doy_e = self.doy_emb(f_doy)\n",
        "\n",
        "        ctx_rep   = context.unsqueeze(1).repeat(1, HZ, 1)\n",
        "        item_rep2 = item_e.unsqueeze(1).repeat(1, HZ, 1)\n",
        "        shop_rep2 = shop_e.unsqueeze(1).repeat(1, HZ, 1)\n",
        "\n",
        "        dec_in = torch.cat([ctx_rep, item_rep2, shop_rep2,\n",
        "                            f_dow_e, f_mon_e, f_woy_e, f_doy_e, pos_e], dim=-1)\n",
        "        out = self.head(dec_in).squeeze(-1)  # (B,HZ)\n",
        "        return out\n",
        "\n",
        "# 모델/옵티마/스케줄러\n",
        "model = GlobalGRUForecaster(\n",
        "    n_items=N_ITEMS, n_shops=N_SHOPS,\n",
        "    item_emb_dim=32, shop_emb_dim=8,\n",
        "    dow_emb_dim=4, mon_emb_dim=4, woy_emb_dim=6, doy_emb_dim=8,\n",
        "    horizon_emb_dim=8, hidden_dim=128, num_layers=2,\n",
        "    horizon=HORIZON, dropout=0.15\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
        "mse_loss  = nn.MSELoss(reduction='none')  # 샘플 가중 적용 위해\n"
      ],
      "metadata": {
        "id": "KW6XO4HRHXMY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 빠른 점검: 한 배치 뽑아서 인덱스 범위 확인\n",
        "b = next(iter(train_loader))\n",
        "print(\"len(batch) =\", len(b))\n",
        "# 여기서 다시 최소/최대 찍어봐도 되고, 이제부터는 forward에서 강제로 정리하니 학습이 진행될 거예요.\n",
        "\n",
        "if len(b) == 16:\n",
        "    (xb, xrm7b, xrm28b,\n",
        "     xdw, xmn, xwy, xdy,\n",
        "     yb, iid, sid, wb, sc,\n",
        "     fdw, fmn, fwy, fdy) = b\n",
        "\n",
        "    print(\"item_emb size:\", model.item_emb.num_embeddings, \"min/max iid:\", iid.min().item(), iid.max().item())\n",
        "    print(\"shop_emb size:\", model.shop_emb.num_embeddings, \"min/max sid:\", sid.min().item(), sid.max().item())\n",
        "    print(\"dow_emb  size:\", model.dow_emb.num_embeddings,  \"min/max xdw:\", xdw.min().item(), xdw.max().item(),\n",
        "          \"min/max fdw:\", fdw.min().item(), fdw.max().item())\n",
        "    print(\"mon_emb  size:\", model.mon_emb.num_embeddings,  \"min/max xmn:\", xmn.min().item(), xmn.max().item(),\n",
        "          \"min/max fmn:\", fmn.min().item(), fmn.max().item())\n",
        "    print(\"woy_emb  size:\", model.woy_emb.num_embeddings,  \"min/max xwy:\", xwy.min().item(), xwy.max().item(),\n",
        "          \"min/max fwy:\", fwy.min().item(), fwy.max().item())\n",
        "    print(\"doy_emb  size:\", model.doy_emb.num_embeddings,  \"min/max xdy:\", xdy.min().item(), xdy.max().item(),\n",
        "          \"min/max fdy:\", fdy.min().item(), fdy.max().item())\n",
        "elif len(b) == 8:\n",
        "    xb, xdw, fdw, yb, iid, sid, wb, sc = b\n",
        "    print(\"item_emb size:\", model.item_emb.num_embeddings, \"min/max iid:\", iid.min().item(), iid.max().item())\n",
        "    print(\"shop_emb size:\", model.shop_emb.num_embeddings, \"min/max sid:\", sid.min().item(), sid.max().item())\n",
        "    print(\"dow_emb  size:\", model.dow_emb.num_embeddings,  \"min/max xdw:\", xdw.min().item(), xdw.max().item(),\n",
        "          \"min/max fdw:\", fdw.min().item(), fdw.max().item())\n",
        "else:\n",
        "    print(\"Unexpected batch length:\", len(b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QDXGtdhbbm9",
        "outputId": "e1f1293a-4913-41ec-dfe6-5a0ce45f2a07"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(batch) = 16\n",
            "item_emb size: 194 min/max iid: 1 193\n",
            "shop_emb size: 10 min/max sid: 1 9\n",
            "dow_emb  size: 7 min/max xdw: 0 6 min/max fdw: 0 6\n",
            "mon_emb  size: 13 min/max xmn: 1 12 min/max fmn: 1 12\n",
            "woy_emb  size: 55 min/max xwy: 1 52 min/max fwy: 1 52\n",
            "doy_emb  size: 367 min/max xdy: 1 365 min/max fdy: 1 365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Training / Validation (안정 가드 포함)\n",
        "# -------------------------\n",
        "def _clamp_idx_like_module(x, emb):\n",
        "    hi = emb.num_embeddings - 1\n",
        "    return x.long().clamp(min=0, max=hi)\n",
        "\n",
        "def _ensure_1d_ids_lenB(x, B):\n",
        "    if not torch.is_tensor(x):\n",
        "        x = torch.tensor(x)\n",
        "    if x.dim() == 0:\n",
        "        x = x.view(1).repeat(B)\n",
        "    elif x.dim() >= 2:\n",
        "        x = x.view(B, -1)[:, 0]\n",
        "    elif x.size(0) != B:\n",
        "        x = x[:1].repeat(B)\n",
        "    return x.long()\n",
        "\n",
        "def run_epoch(loader, is_train=True):\n",
        "    model.train() if is_train else model.eval()\n",
        "    total_loss, total_smape, total_n = 0.0, 0.0, 0\n",
        "\n",
        "    for batch in loader:\n",
        "        (xb, xrm7b, xrm28b,\n",
        "         xdw, xmn, xwy, xdy,\n",
        "         yb, iid, sid, wb, sc,\n",
        "         fdw, fmn, fwy, fdy) = batch\n",
        "\n",
        "        B = xb.size(0)\n",
        "        xb, xrm7b, xrm28b = xb.to(DEVICE), xrm7b.to(DEVICE), xrm28b.to(DEVICE)\n",
        "        yb  = yb.to(DEVICE)\n",
        "        wb  = wb.to(DEVICE)\n",
        "        sc  = sc.to(DEVICE)\n",
        "\n",
        "        iid = _ensure_1d_ids_lenB(iid.to(DEVICE), B)\n",
        "        sid = _ensure_1d_ids_lenB(sid.to(DEVICE), B)\n",
        "\n",
        "        xdw = _clamp_idx_like_module(xdw.to(DEVICE), model.dow_emb)\n",
        "        xmn = _clamp_idx_like_module(xmn.to(DEVICE), model.mon_emb)\n",
        "        xwy = _clamp_idx_like_module(xwy.to(DEVICE), model.woy_emb)\n",
        "        xdy = _clamp_idx_like_module(xdy.to(DEVICE), model.doy_emb)\n",
        "        fdw = _clamp_idx_like_module(fdw.to(DEVICE), model.dow_emb)\n",
        "        fmn = _clamp_idx_like_module(fmn.to(DEVICE), model.mon_emb)\n",
        "        fwy = _clamp_idx_like_module(fwy.to(DEVICE), model.woy_emb)\n",
        "        fdy = _clamp_idx_like_module(fdy.to(DEVICE), model.doy_emb)\n",
        "\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            pred_scaled = model(\n",
        "                xb, xrm7b, xrm28b,\n",
        "                xdw, xmn, xwy, xdy,\n",
        "                iid, sid,\n",
        "                fdw, fmn, fwy, fdy\n",
        "            )  # (B,HZ)\n",
        "\n",
        "            # 안정화: 스케일 공간에서 gradient 폭주 방지\n",
        "            pred_scaled = torch.clamp(pred_scaled, -20.0, 20.0)\n",
        "            yb          = torch.clamp(yb,         -20.0, 20.0)\n",
        "\n",
        "            # MSE (scaled space) → 샘플별 평균 → 가중 평균\n",
        "            mse_per_t = mse_loss(pred_scaled, yb).mean(dim=1)   # (B,)\n",
        "            loss_mse_weighted = (mse_per_t * wb).mean()\n",
        "\n",
        "            # 원 스케일 복원\n",
        "            pred_orig = torch.exp(pred_scaled * sc) - 1.0\n",
        "            true_orig = torch.exp(yb          * sc) - 1.0\n",
        "            pred_orig = torch.nan_to_num(pred_orig, nan=0.0, posinf=0.0, neginf=0.0).clamp_min(0.0)\n",
        "            true_orig = torch.nan_to_num(true_orig, nan=0.0, posinf=0.0, neginf=0.0).clamp_min(0.0)\n",
        "\n",
        "            # Weighted SMAPE\n",
        "            loss_smape_weighted = smape_torch_weighted(true_orig, pred_orig, wb)\n",
        "\n",
        "            # 최종 손실 (SMAPE에 더 가중)\n",
        "            loss = ALPHA_SM * loss_smape_weighted + (1.0 - ALPHA_SM) * loss_mse_weighted\n",
        "\n",
        "            if is_train:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss  += float(loss.item()) * B\n",
        "        total_smape += float(loss_smape_weighted.item()) * B\n",
        "        total_n     += B\n",
        "\n",
        "    return total_loss/total_n, total_smape/total_n\n",
        "\n",
        "best_val = float('inf')\n",
        "pat_cnt  = 0\n",
        "best_state = None\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_smape = run_epoch(train_loader, is_train=True)\n",
        "    va_loss, va_smape = run_epoch(valid_loader, is_train=False)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"[{epoch:02d}] train loss={tr_loss:.5f} smape={tr_smape:.5f} | \"\n",
        "          f\"valid loss={va_loss:.5f} smape={va_smape:.5f}\")\n",
        "\n",
        "    if va_smape < best_val:\n",
        "        best_val = va_smape\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "        pat_cnt = 0\n",
        "    else:\n",
        "        pat_cnt += 1\n",
        "        if pat_cnt >= PATIENCE:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLJKL7ixHdgz",
        "outputId": "bf96b55d-436c-4f95-9c94-f179b6d1d7d3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01] train loss=1.39533 smape=0.59882 | valid loss=1.12156 smape=0.66794\n",
            "[02] train loss=1.16446 smape=0.53441 | valid loss=1.09291 smape=0.68835\n",
            "[03] train loss=1.03209 smape=0.50210 | valid loss=1.09451 smape=0.67697\n",
            "[04] train loss=0.93001 smape=0.47950 | valid loss=1.09435 smape=0.64529\n",
            "[05] train loss=0.85218 smape=0.46263 | valid loss=1.10844 smape=0.64889\n",
            "[06] train loss=0.78383 smape=0.44719 | valid loss=1.11342 smape=0.64749\n",
            "[07] train loss=0.73089 smape=0.43374 | valid loss=1.10344 smape=0.64813\n",
            "[08] train loss=0.68032 smape=0.42001 | valid loss=1.19251 smape=0.67314\n",
            "[09] train loss=0.64244 smape=0.40775 | valid loss=1.19124 smape=0.65761\n",
            "[10] train loss=0.60547 smape=0.39604 | valid loss=1.17226 smape=0.67485\n",
            "Early stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GlobalGRUForecaster(\n",
              "  (item_emb): Embedding(194, 32)\n",
              "  (shop_emb): Embedding(10, 8)\n",
              "  (dow_emb): Embedding(7, 4)\n",
              "  (mon_emb): Embedding(13, 4)\n",
              "  (woy_emb): Embedding(55, 6)\n",
              "  (doy_emb): Embedding(367, 8)\n",
              "  (h_emb): Embedding(7, 8)\n",
              "  (encoder): GRU(65, 128, num_layers=2, batch_first=True, dropout=0.15)\n",
              "  (head): Sequential(\n",
              "    (0): Linear(in_features=198, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.15, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Inference on TEST_*.csv (STRICT: 28일 입력)\n",
        "# -------------------------\n",
        "def predict_file(test_path: str):\n",
        "    df = pd.read_csv(test_path)\n",
        "    df[\"영업일자\"] = pd.to_datetime(df[\"영업일자\"])\n",
        "    df[\"영업장명_메뉴명\"] = df[\"영업장명_메뉴명\"].astype(str)\n",
        "    df[\"업장명\"] = df[\"영업장명_메뉴명\"].apply(parse_shop)\n",
        "    df = df.sort_values([\"영업장명_메뉴명\", \"영업일자\"]).reset_index(drop=True)\n",
        "\n",
        "    rows = []\n",
        "    for it, g in df.groupby(\"영업장명_메뉴명\"):\n",
        "        g = g.sort_values(\"영업일자\")\n",
        "        if len(g) < LOOKBACK:\n",
        "            continue\n",
        "\n",
        "        vals = _clean_counts(g[\"매출수량\"].values[-LOOKBACK:])\n",
        "        dts  = pd.to_datetime(g[\"영업일자\"].values[-LOOKBACK:])\n",
        "        x_dow = dts.dayofweek.values.astype(np.int64)\n",
        "        x_mon = dts.month.values.astype(np.int64)\n",
        "        x_woy = dts.isocalendar().week.values.astype(np.int64)\n",
        "        x_doy = dts.dayofyear.values.astype(np.int64)\n",
        "\n",
        "        s = pd.Series(vals)\n",
        "        x_rm7  = s.rolling(7,  min_periods=1).mean().values\n",
        "        x_rm28 = s.rolling(28, min_periods=1).mean().values\n",
        "\n",
        "        iid = item2id.get(it, UNK_ITEM)\n",
        "        shop = parse_shop(it)\n",
        "        sid  = shop2id.get(shop, UNK_SHOP)\n",
        "\n",
        "        x_log    = np.log1p(vals)\n",
        "        rm7_log  = np.log1p(np.maximum(x_rm7,  0.0))\n",
        "        rm28_log = np.log1p(np.maximum(x_rm28, 0.0))\n",
        "        scale = float(np.nanmean(x_log))\n",
        "        if not np.isfinite(scale) or abs(scale) < 1e-8:\n",
        "            scale = 1.0\n",
        "\n",
        "        x     = (x_log   / scale).astype(np.float32)\n",
        "        xrm7  = (rm7_log / scale).astype(np.float32)\n",
        "        xrm28 = (rm28_log/ scale).astype(np.float32)\n",
        "\n",
        "        last_date = pd.to_datetime(dts[-1])\n",
        "        fut_dates = [last_date + pd.Timedelta(days=k) for k in range(1, HORIZON+1)]\n",
        "        f_dow = np.array([d.dayofweek          for d in fut_dates], dtype=np.int64)\n",
        "        f_mon = np.array([d.month              for d in fut_dates], dtype=np.int64)\n",
        "        f_woy = np.array([d.isocalendar().week for d in fut_dates], dtype=np.int64)\n",
        "        f_doy = np.array([d.dayofyear          for d in fut_dates], dtype=np.int64)\n",
        "\n",
        "        xb     = torch.from_numpy(x[None, :]).to(DEVICE)\n",
        "        xrm7b  = torch.from_numpy(xrm7[None, :]).to(DEVICE)\n",
        "        xrm28b = torch.from_numpy(xrm28[None, :]).to(DEVICE)\n",
        "\n",
        "        xdw = torch.from_numpy(x_dow[None, :]).long().to(DEVICE)\n",
        "        xmn = torch.from_numpy(x_mon[None, :]).long().to(DEVICE)\n",
        "        xwy = torch.from_numpy(x_woy[None, :]).long().to(DEVICE)\n",
        "        xdy = torch.from_numpy(x_doy[None, :]).long().to(DEVICE)\n",
        "\n",
        "        fdw = torch.from_numpy(f_dow[None, :]).long().to(DEVICE)\n",
        "        fmn = torch.from_numpy(f_mon[None, :]).long().to(DEVICE)\n",
        "        fwy = torch.from_numpy(f_woy[None, :]).long().to(DEVICE)\n",
        "        fdy = torch.from_numpy(f_doy[None, :]).long().to(DEVICE)\n",
        "\n",
        "        iid_t = torch.tensor([iid], dtype=torch.long, device=DEVICE)\n",
        "        sid_t = torch.tensor([sid], dtype=torch.long, device=DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(\n",
        "                xb, xrm7b, xrm28b,\n",
        "                xdw, xmn, xwy, xdy,\n",
        "                iid_t, sid_t,\n",
        "                fdw, fmn, fwy, fdy\n",
        "            )\n",
        "            pred_scaled = torch.clamp(pred_scaled, -20.0, 20.0)\n",
        "            pred_orig   = torch.exp(pred_scaled * torch.tensor([[scale]], device=DEVICE)) - 1.0\n",
        "            pred_orig   = torch.clamp(pred_orig, min=0.0).squeeze(0).cpu().numpy()\n",
        "\n",
        "        rows.append({\"영업장명_메뉴명\": it, \"업장명\": shop, \"preds\": pred_orig})\n",
        "\n",
        "    filename = os.path.basename(test_path)\n",
        "    prefix = re.search(r\"(TEST_\\d+)\", filename).group(1)\n",
        "    out_rows = []\n",
        "    for r in rows:\n",
        "        for i, v in enumerate(r[\"preds\"], start=1):\n",
        "            out_rows.append({\n",
        "                \"영업일자\": f\"{prefix}+{i}일\",\n",
        "                \"영업장명_메뉴명\": r[\"영업장명_메뉴명\"],\n",
        "                \"매출수량\": float(v)\n",
        "            })\n",
        "    return pd.DataFrame(out_rows)\n",
        "\n",
        "# 모든 TEST 파일 예측 & 합치기\n",
        "test_paths = sorted(glob.glob(TEST_GLOB))\n",
        "print(\"TEST files:\", len(test_paths), test_paths[:3], \"...\")\n",
        "if len(test_paths) == 0:\n",
        "    raise RuntimeError(\"TEST_*.csv가 없습니다. /data/test/ 하위 확인\")\n",
        "\n",
        "all_preds = []\n",
        "for p in test_paths:\n",
        "    df_pred = predict_file(p)\n",
        "    if len(df_pred) == 0:\n",
        "        print(f\"경고: {os.path.basename(p)} 예측 결과가 비었습니다. (28일 미만 샘플?)\")\n",
        "    all_preds.append(df_pred)\n",
        "\n",
        "full_pred_df = pd.concat(all_preds, ignore_index=True)\n",
        "print(\"full_pred_df shape:\", full_pred_df.shape)\n",
        "# display(full_pred_df.head())  # Colab이면 주석 해제해 확인 가능\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8dzhAUHeSu",
        "outputId": "e838eba0-ea46-46d9-d5b0-110acec9ad5b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST files: 10 ['/data/test/TEST_00.csv', '/data/test/TEST_01.csv', '/data/test/TEST_02.csv'] ...\n",
            "full_pred_df shape: (13510, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 모든 TEST 파일 예측 & 합치기\n",
        "# -------------------------\n",
        "import glob, os\n",
        "\n",
        "TEST_GLOB = \"/data/test/TEST_*.csv\"\n",
        "test_paths = sorted(glob.glob(TEST_GLOB))\n",
        "print(\"TEST files:\", len(test_paths), test_paths[:3], \" ...\")\n",
        "\n",
        "if len(test_paths) == 0:\n",
        "    raise RuntimeError(\"TEST_*.csv 파일을 찾지 못했습니다. /data/test/ 아래에 TEST_00.csv ~ TEST_09.csv 확인\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "for p in test_paths:\n",
        "    df_pred = predict_file(p)\n",
        "    if len(df_pred) == 0:\n",
        "        print(f\"경고: {os.path.basename(p)} 예측 결과가 비었습니다. (28일 미만 샘플?)\")\n",
        "    all_preds.append(df_pred)\n",
        "\n",
        "full_pred_df = pd.concat(all_preds, ignore_index=True)\n",
        "print(\"full_pred_df shape:\", full_pred_df.shape)\n",
        "display(full_pred_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "GpeGerexYP0q",
        "outputId": "0582b688-d763-4bac-a3f7-e7343d57d061"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST files: 10 ['/data/test/TEST_00.csv', '/data/test/TEST_01.csv', '/data/test/TEST_02.csv']  ...\n",
            "full_pred_df shape: (13510, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         영업일자            영업장명_메뉴명      매출수량\n",
              "0  TEST_00+1일  느티나무 셀프BBQ_1인 수저세트  7.727566\n",
              "1  TEST_00+2일  느티나무 셀프BBQ_1인 수저세트  2.126642\n",
              "2  TEST_00+3일  느티나무 셀프BBQ_1인 수저세트  3.101673\n",
              "3  TEST_00+4일  느티나무 셀프BBQ_1인 수저세트  2.916096\n",
              "4  TEST_00+5일  느티나무 셀프BBQ_1인 수저세트  4.198502"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-886690f7-ac42-4234-a90e-104a4fcc6b2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>영업일자</th>\n",
              "      <th>영업장명_메뉴명</th>\n",
              "      <th>매출수량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_00+1일</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>7.727566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_00+2일</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>2.126642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_00+3일</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>3.101673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_00+4일</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>2.916096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_00+5일</td>\n",
              "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
              "      <td>4.198502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-886690f7-ac42-4234-a90e-104a4fcc6b2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-886690f7-ac42-4234-a90e-104a4fcc6b2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-886690f7-ac42-4234-a90e-104a4fcc6b2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-44c16655-29a7-4f32-8007-33a090b78320\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44c16655-29a7-4f32-8007-33a090b78320')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-44c16655-29a7-4f32-8007-33a090b78320 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(full_pred_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc77c\\uc790\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"TEST_00+2\\uc77c\",\n          \"TEST_00+5\\uc77c\",\n          \"TEST_00+3\\uc77c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc601\\uc5c5\\uc7a5\\uba85_\\uba54\\ub274\\uba85\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\ub290\\ud2f0\\ub098\\ubb34 \\uc140\\ud504BBQ_1\\uc778 \\uc218\\uc800\\uc138\\ud2b8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9e4\\ucd9c\\uc218\\ub7c9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.203659801233042,\n        \"min\": 2.1266415119171143,\n        \"max\": 7.727565765380859,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.1266415119171143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Convert to Submission Format\n",
        "# -------------------------\n",
        "def convert_to_submission(pred_df: pd.DataFrame, sample_df: pd.DataFrame):\n",
        "    pred_key = dict(zip(\n",
        "        zip(pred_df[\"영업일자\"], pred_df[\"영업장명_메뉴명\"]),\n",
        "        pred_df[\"매출수량\"]\n",
        "    ))\n",
        "    sub = sample_df.copy()\n",
        "    for r in sub.index:\n",
        "        d = sub.loc[r, \"영업일자\"]\n",
        "        for c in sub.columns[1:]:\n",
        "            sub.loc[r, c] = pred_key.get((d, c), 0.0)\n",
        "    return sub\n",
        "\n",
        "sample = pd.read_csv(SAMPLE_SUB) if os.path.exists(SAMPLE_SUB) \\\n",
        "         else pd.read_csv(\"/data/sample_submission/sample_submission.csv\")\n",
        "submission = convert_to_submission(full_pred_df, sample)\n",
        "\n",
        "OUT_PATH = \"/data/submission_global_gru.csv\"\n",
        "submission.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"Saved submission -> {OUT_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmiH9lwgnFEu",
        "outputId": "c717ab6a-65d2-4c54-bfce-3d56d8360c42"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission -> /data/submission_global_gru.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# (Optional) Offline validation (확장 피처용)  ← unpack 16개!\n",
        "# -------------------------\n",
        "def offline_validation_score_ext(valid_loader):\n",
        "    model.eval()\n",
        "    ys, ps, ws = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_loader:\n",
        "            (xb, xrm7b, xrm28b,\n",
        "             xdw, xmn, xwy, xdy,\n",
        "             yb, iid, sid, wb, sc,\n",
        "             fdw, fmn, fwy, fdy) = batch\n",
        "\n",
        "            B = xb.size(0)\n",
        "            xb, xrm7b, xrm28b = xb.to(DEVICE), xrm7b.to(DEVICE), xrm28b.to(DEVICE)\n",
        "            yb  = yb.to(DEVICE)\n",
        "            wb  = wb.to(DEVICE)\n",
        "            sc  = sc.to(DEVICE)\n",
        "\n",
        "            iid = _ensure_1d_ids_lenB(iid.to(DEVICE), B)\n",
        "            sid = _ensure_1d_ids_lenB(sid.to(DEVICE), B)\n",
        "\n",
        "            xdw = _clamp_idx_like_module(xdw.to(DEVICE), model.dow_emb)\n",
        "            xmn = _clamp_idx_like_module(xmn.to(DEVICE), model.mon_emb)\n",
        "            xwy = _clamp_idx_like_module(xwy.to(DEVICE), model.woy_emb)\n",
        "            xdy = _clamp_idx_like_module(xdy.to(DEVICE), model.doy_emb)\n",
        "            fdw = _clamp_idx_like_module(fdw.to(DEVICE), model.dow_emb)\n",
        "            fmn = _clamp_idx_like_module(fmn.to(DEVICE), model.mon_emb)\n",
        "            fwy = _clamp_idx_like_module(fwy.to(DEVICE), model.woy_emb)\n",
        "            fdy = _clamp_idx_like_module(fdy.to(DEVICE), model.doy_emb)\n",
        "\n",
        "            pred_scaled = model(\n",
        "                xb, xrm7b, xrm28b,\n",
        "                xdw, xmn, xwy, xdy,\n",
        "                iid, sid,\n",
        "                fdw, fmn, fwy, fdy\n",
        "            )\n",
        "            pred_scaled = torch.clamp(pred_scaled, -20.0, 20.0)\n",
        "            yb          = torch.clamp(yb,         -20.0, 20.0)\n",
        "\n",
        "            pred_orig = torch.exp(pred_scaled * sc) - 1.0\n",
        "            true_orig = torch.exp(yb          * sc) - 1.0\n",
        "            pred_orig = torch.nan_to_num(pred_orig, nan=0.0, posinf=0.0, neginf=0.0).clamp_min(0.0)\n",
        "            true_orig = torch.nan_to_num(true_orig, nan=0.0, posinf=0.0, neginf=0.0).clamp_min(0.0)\n",
        "\n",
        "            ys.append(true_orig.cpu().numpy())\n",
        "            ps.append(pred_orig.cpu().numpy())\n",
        "            ws.append(wb.cpu().numpy())\n",
        "\n",
        "    y = np.concatenate(ys, axis=0)   # (N,HZ)\n",
        "    p = np.concatenate(ps, axis=0)   # (N,HZ)\n",
        "    w = np.concatenate(ws, axis=0).reshape(-1, 1)  # (N,1)\n",
        "\n",
        "    mask = (y != 0).astype(np.float32)\n",
        "    num  = 2.0 * np.abs(y - p)\n",
        "    den  = np.abs(y) + np.abs(p) + 1e-5\n",
        "    sm   = (num / den) * mask\n",
        "    per_sample = sm.sum(axis=1) / np.clip(mask.sum(axis=1), 1.0, None)\n",
        "    score = float((per_sample.reshape(-1,1) * w).sum() / np.clip(w.sum(), 1.0, None))\n",
        "    return score\n",
        "\n",
        "try:\n",
        "    approx_smape_w = offline_validation_score_ext(valid_loader)\n",
        "    print(f\"[Offline weighted SMAPE] {approx_smape_w:.6f}\")\n",
        "except Exception as e:\n",
        "    print(\"Offline validation skipped:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMf4CN1Am59h",
        "outputId": "b1883f24-90b6-4d0b-b46f-48ff1d0dd61e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Offline weighted SMAPE] 0.652261\n"
          ]
        }
      ]
    }
  ]
}